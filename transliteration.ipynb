{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dhruv3110/Roman-to-Devanagari-Transliteration-System/blob/main/transliteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjhLTXD5W7TN"
   },
   "source": [
    "Load Dataset -> Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuKb0l1bczEh",
    "outputId": "42867403-2be7-44bf-f4e0-fc55b359f5b3"
   },
   "outputs": [],
   "source": [
    "!pip install nbstripout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DtF4jo9WGBc",
    "outputId": "8ca3580b-3abf-404e-b839-491b9f3bc422"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjhLHY2_uVgv"
   },
   "outputs": [],
   "source": [
    "!pip install datasets unsloth jiwer evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEhQCx2TSNLf"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "import os\n",
    "from transformers import TrainingArguments\n",
    "from unsloth.trainer import SFTTrainer\n",
    "from jiwer import wer, cer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm = lambda x, **kwargs: x\n",
    "\n",
    "\n",
    "login()\n",
    "\n",
    "ds = load_dataset(\"codebyam/Hinglish-Hindi-Transliteration-Dataset\", split=\"train\")\n",
    "df = ds.to_pandas()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzhnSYJ3XADH"
   },
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iYsO4C8U9gD",
    "outputId": "61dceb4e-f25c-43ac-97cd-bce12287e417"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Hinglish': 'Roman'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0T-_2RCY4x5"
   },
   "source": [
    "SOFT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5LVs6nuYauI",
    "outputId": "e2bc851f-ed23-4670-fde2-790c523d2989"
   },
   "outputs": [],
   "source": [
    "def soft_clean_row(row):\n",
    "    roman, hindi = row[\"Roman\"], row[\"Hindi\"]\n",
    "\n",
    "    if not isinstance(roman, str) or not isinstance(hindi, str):\n",
    "        return None\n",
    "\n",
    "    roman = roman.lower().strip()\n",
    "    roman = re.sub(r\"[^a-z0-9\\s'!?.,\\-]\", \"\", roman)\n",
    "\n",
    "    hindi = hindi.strip()\n",
    "    hindi = re.sub(r\"[^\\u0900-\\u097F\\sред!?]\", \"\", hindi)\n",
    "\n",
    "    if not roman or not hindi:\n",
    "        return None\n",
    "\n",
    "    return {\"roman\": roman, \"hindi\": hindi}\n",
    "\n",
    "df = df.apply(soft_clean_row, axis=1).dropna().apply(pd.Series)\n",
    "print(\"After cleaning:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5OS2CXoY7NI"
   },
   "source": [
    "NOISE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znESNtHEYe9D",
    "outputId": "753e806e-0aab-40d9-97b8-c8047a93cc2a"
   },
   "outputs": [],
   "source": [
    "HINGLISH_SLANG = {\n",
    "    \"m\",\"me\",\"mai\",\"main\",\"yr\",\"yaar\",\"bro\",\"bruh\",\"kr\",\"krr\",\"kya\",\"kyu\",\"kyun\",\n",
    "    \"h\",\"hu\",\"hun\",\"rha\",\"rhi\",\"rhe\",\"plz\",\"pls\",\"sry\",\"thx\",\"bht\",\"lol\",\"lmao\"\n",
    "}\n",
    "\n",
    "HINGLISH_CONSONANT_TOKENS = {\"kl\",\"tb\",\"jb\",\"thk\",\"hn\",\"thn\",\"kch\",\"smj\"}\n",
    "\n",
    "def noise_score(roman):\n",
    "    score = 0\n",
    "    tokens = roman.split()\n",
    "\n",
    "    score += bool(re.search(r\"(.)\\1{2,}\", roman))\n",
    "    score += sum(t in HINGLISH_SLANG for t in tokens)\n",
    "    score += sum(t in HINGLISH_CONSONANT_TOKENS for t in tokens)\n",
    "    score += sum(re.fullmatch(r\"[bcdfghjklmnpqrstvwxyz]+\", t) is not None for t in tokens)\n",
    "    score += bool(re.search(r\"[a-z]\\d[a-z]\", roman))\n",
    "    score += bool(re.search(r\"([!?.,])\\1{1,}\", roman))\n",
    "\n",
    "    return score\n",
    "\n",
    "df[\"noise_score\"] = df[\"roman\"].apply(noise_score)\n",
    "df[\"is_noisy\"] = (df[\"noise_score\"] > 0).astype(int)\n",
    "\n",
    "print(\"Noise ratio:\", df[\"is_noisy\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvnrg7ltZNMo"
   },
   "source": [
    "DATA AUGMENTATION (Clean + Controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "s10-0GywY_XG",
    "outputId": "ea3065f8-6be7-4502-da16-d759e60d2501"
   },
   "outputs": [],
   "source": [
    "def augment_pair(roman, hindi, noise):\n",
    "    pairs = [(roman, hindi)]\n",
    "    rules = {\n",
    "        \"aa\": [\"a\"], \"ee\": [\"i\"], \"oo\": [\"u\"],\n",
    "        \"sh\": [\"s\"], \"ch\": [\"c\"], \"th\": [\"t\"]\n",
    "    }\n",
    "\n",
    "    for k, vs in rules.items():\n",
    "        if k in roman:\n",
    "            for v in vs:\n",
    "                pairs.append((roman.replace(k, v), hindi))\n",
    "\n",
    "    max_rep = 2 + min(noise, 2)\n",
    "    r2 = re.sub(r\"([aeiou])\", r\"\\1\"*max_rep, roman, count=1)\n",
    "    if r2 != roman:\n",
    "        pairs.append((r2, hindi))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "augmented = []\n",
    "for r, h, nz in df[[\"roman\",\"hindi\",\"noise_score\"]].values:\n",
    "    augmented.extend(augment_pair(r, h, nz))\n",
    "\n",
    "df = pd.DataFrame(augmented, columns=[\"roman\", \"hindi\"])\n",
    "print(\"After augmentation:\", len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IRaP8D8ZRWe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjbW7evqZniU"
   },
   "source": [
    "PROMPT CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMl7u9wMZeBb",
    "outputId": "4ae2dd7c-216e-4b27-858a-5d764b6e0499"
   },
   "outputs": [],
   "source": [
    "def make_prompt(row):\n",
    "    return f\"\"\"### Instruction:\n",
    "Convert Hinglish (Roman Hindi) into Hindi (Devanagari script).\n",
    "Be robust to slang, shortcuts, repeated letters & noisy spellings.\n",
    "\n",
    "### Input:\n",
    "{row['roman']}\n",
    "\n",
    "### Output:\n",
    "{row['hindi']}\"\"\"\n",
    "\n",
    "df[\"prompt\"] = df.apply(make_prompt, axis=1)\n",
    "print(df.iloc[0][\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNCU-TG4Zy3P"
   },
   "source": [
    "Convert BACK to HF Dataset (only now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvRjKPPuZqAE"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(df, preserve_index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiVE2P30eN0z"
   },
   "source": [
    "Load Model + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411,
     "referenced_widgets": [
      "29b657bf07224ed8a5c2e7cb1e3a9658",
      "4ea923afaabd4fe398e6ed7ba2031b27",
      "1f98875323984eec9c6d395840249844",
      "d670eb8c64134680a18bad90abc6b6c7",
      "52f7356c1f4a47278d8f3ba271986957",
      "c4bb9b3ec5ba4c63ad86c4c1852c8952",
      "7af8daa7f4854b3ebd12342d13732ced",
      "3df42df392c44a84a237fb1cbc28bd8a",
      "ab078a2083724e3280a8eddf97fd7507",
      "682ed0328a9f4e3ca3556755aa4e4d5c",
      "192082889e474b478df9057133c18cf7",
      "5b8cbd93dade42c7877b6db2dec05b6c",
      "df011c7b36b74b51b39f7fb8162d58e6",
      "6fe604c5064b47ceb2f44a1f58b02628",
      "80464c4b713641d7abbee231f2141c55",
      "bac5a182bad243238bcfc87258ed8d13",
      "307446691005428b8603751c0f5a8937",
      "86868040cb5944c3b2612c9436cf320b",
      "3d34d49669c640ce82e6d04d9be5a421",
      "2497db90871f4a5488774d7fa86cadd2",
      "d6ce195791c7497cbc76e9fd39b70268",
      "90a8f91e98a444588b02df8eeb18bed6",
      "133ab356972147ea92eb792e1ae8519f",
      "df1eeca592dc4b7ead63b15de05e67b4",
      "5ad6494ae78c43c2961c4c2aa6bbca86",
      "291987f1ece549a2961527a78c7f2cf6",
      "0712fb72fd4d4967a6d0ef0ae51ca517",
      "e02881ed7b734bc0b1c41d7ef7a4ddfc",
      "8996f76f41a3452da6d9c39b09e9629b",
      "e751135592c44ece8e09e29b7b0987d7",
      "47545d2f909749439988f26ddbd18d7b",
      "c62bcbb6d72340f09ebaddc4395ac552",
      "9ff1b215ca954a288dd04c3c393bfcd5",
      "4b6c3ec6d7814f8eb1dfe1dd1f40300e",
      "304d83e1e5f34baaad66b1da40088576",
      "ad5a8bdd09494fa4b6f7b628966deba3",
      "78c7710a82d54b41a07f499cedb5daaf",
      "4e40d2bef01f4de694c067bc939f0ed1",
      "25004d10e4f944fe905e3e1f615246cb",
      "c295579288af4af2b0b14a122ea28bf3",
      "b004ac19852a4123a685a048987e249b",
      "d5222f8078324d1f94f42683256f02f3",
      "7a87215b9f8246ec9cfbb19ca72e2b98",
      "1ccd754f590744b4b89ed149d4757866",
      "393916bd278b4d4b98d8377f45ea5c80",
      "f9e49ce550254f76ad9c1ae092617d4c",
      "8e722393b8d0489ba3810956f11157fb",
      "115e5c078ac74033bba36cf441f277bd",
      "668d504daa0747328ba8a4f6a1ae648e",
      "6a00b671e4684e139dc9ba77de05ba31",
      "f86eefb85927467ababf7312c40fe4ef",
      "0a90c2b842cb4cc28b9a7bd46166f201",
      "0a8a235a7d1846d4b7e98f625c35e38c",
      "80e2c4ab4ac54cf2ae70e74399fe1a8d",
      "11414b08461c4a138be6dcba3d1ce1df",
      "95d53069c1d14298886bf919b6d52ae4",
      "bed2b39ead954cb084203f3528d3eef3",
      "fe26dcaaccd84289ac286bf087827b93",
      "3244358eb9294074bc70f3ce027f82e6",
      "554ff17bdd0a499fb157b71182b0c6a7",
      "007287ca821f4d1cb465a32548c9a134",
      "fa075bf05ff5469a807c0aa278cd9229",
      "e7933c82ea9349b3937568ee963b807f",
      "88115f6d6d4a404ba540d95e034e7ebd",
      "f4d710104d3642b38567303494347d17",
      "8931fde763974fb6903ee5fbd0a421d3"
     ]
    },
    "id": "cbfwp9S5aFYF",
    "outputId": "e078c1c4-7085-4d09-ff91-4ff916b60252"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    max_seq_length=512,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    ")\n",
    "\n",
    "print(\"Gemma 2B + LoRA loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_heZdkueex0"
   },
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "c85b32fe4c874c8f80272bcf03819256",
      "92d98c56b8b146ac9a9b8049d3430762",
      "af18607463e84930a866d1e0be03a668",
      "a482a776c14d4f71b3114c8d0ac93bae",
      "036a4bba13934e01a3ff630285b203c0",
      "a2f2141216af49c8800e7253e82093b4",
      "31462990c9bd40ad83bb8a7d6de15b14",
      "235d752ecbfe405f8ef481fe35dc7a8e",
      "b84daf31db584b15bff4733436a22cbb",
      "165b84b7f41941af9a215e421ce1af31",
      "36da0986d885418894c2d9170d10ef0c"
     ]
    },
    "id": "k-NHsMKDaLcN",
    "outputId": "c27f2ed7-f2f5-45fb-e75f-848e4ab89793"
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"prompt\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized = train_ds.map(tokenize, batched=True)\n",
    "tokenized = tokenized.remove_columns(\n",
    "    [c for c in tokenized.column_names if c not in [\"input_ids\", \"attention_mask\"]]\n",
    ")\n",
    "\n",
    "print(\"Tokenization DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN1vEkNQeqoR"
   },
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m_gRYpzTeoE6",
    "outputId": "fbeb8aca-aaf0-4b8e-8daa-daf4588ec07f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from unsloth.trainer import SFTTrainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./gemma2b_hinglish_noise_aug\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=5,\n",
    "    fp16=True,\n",
    "    logging_steps=20,\n",
    "    save_steps=300,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    train_dataset=tokenized,\n",
    "    dataset_text_field=\"prompt\",\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7trJwzGfSAO"
   },
   "source": [
    "SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmgEuxohevFh",
    "outputId": "01af79b5-1214-4bf7-fffb-3db06fd72c66"
   },
   "outputs": [],
   "source": [
    "save_path = \"gemma2b_hinglish_lora\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(\"Model saved at:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IG171oxOtPwB"
   },
   "source": [
    "SMALL EVAL SET + TEXT GENERATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTNyPgRRfWKE"
   },
   "outputs": [],
   "source": [
    "# Take 200 samples for quick evaluation\n",
    "eval_df = df.sample(n=min(200, len(df)), random_state=42)\n",
    "eval_ds = Dataset.from_pandas(eval_df, preserve_index=False)\n",
    "def generate_text(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=64,\n",
    "            do_sample=False\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246,
     "referenced_widgets": [
      "d69cfac21d1b472bac1d7ff6a5f8da37",
      "861245e30e424c32b82b4092a81b5767",
      "a2fca38c29304e3cb5e3818145542590",
      "e330dcd81a4144f8aa86332c5ecaa82e",
      "0b6aab3a5ab246f7b49f97967ca37cac",
      "edae005ff5c444c5a579d8df5cbe3f60",
      "1cbb30102eea4ce6a12e55c5bef71ef2",
      "9c3dcc5d5ed845f8810bcc038e0c56cb",
      "c77f5d2512954ced8bcdf79c7d6c091b",
      "0c0d974433674944897f6a18b30fd6de",
      "591d5df1ad2341569ce846c78f2538a5",
      "2cb7b16ca472467a947bf4a5c08fb2ef",
      "df79690d136643ae9061f5e23b635fc4",
      "7853a74a18fa4ae0811b63277fca16a2",
      "f9c74e6d9bcb4253aedd72d8acc8cdf8",
      "ffa59cc22c8f4da2976eb922a4f7f0df",
      "f1f8ff1cbb104a33b508733d197ee789",
      "c99393657ee04b669d559d7ef7d4e934",
      "c52fed7e117649ce9ad249482111b4f4",
      "224748aad87041da97883b06c5dc7d97",
      "52c7151c693b4785ba43a295cc29cfd0",
      "0efd2eb0b3854fd08824c3fa1a116baf"
     ]
    },
    "id": "eE7L_tg-nRmr",
    "outputId": "78df820f-df0b-4bca-8d0c-769c1d62e750"
   },
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "preds, refs = [], []\n",
    "\n",
    "for ex in tqdm(eval_ds, desc=\"Evaluating\"):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Convert Hinglish (Roman Hindi) into Hindi (Devanagari).\n",
    "Handle slang, shortcuts & noisy spellings.\n",
    "\n",
    "### Input:\n",
    "{ex['roman']}\n",
    "\n",
    "### Output:\n",
    "\"\"\"\n",
    "\n",
    "    gen = generate_text(prompt)\n",
    "\n",
    "    # Extract only model output\n",
    "    if \"### Output:\" in gen:\n",
    "        gen = gen.split(\"### Output:\")[-1].strip()\n",
    "    else:\n",
    "        gen = gen.strip()\n",
    "\n",
    "    preds.append(gen)\n",
    "    refs.append(ex[\"hindi\"])\n",
    "\n",
    "\n",
    "cer_score = cer(refs, preds)\n",
    "wer_score = wer(refs, preds)\n",
    "chrf_score = chrf.compute(predictions=preds, references=refs)[\"score\"]\n",
    "bleu_score = bleu.compute(\n",
    "    predictions=preds,\n",
    "    references=[[r] for r in refs]\n",
    ")[\"score\"]\n",
    "\n",
    "exact_match = np.mean([p == r for p, r in zip(preds, refs)])\n",
    "sentence_char_acc = np.mean([\n",
    "    1 - cer([r], [p]) for p, r in zip(preds, refs)\n",
    "])\n",
    "print(\"===== Evaluation Results =====\")\n",
    "print(f\"CER  : {cer_score:.4f}\")\n",
    "print(f\"WER  : {wer_score:.4f}\")\n",
    "print(f\"chrF : {chrf_score:.2f}\")\n",
    "print(f\"BLEU : {bleu_score:.2f}\")\n",
    "print(f\"Exact Match Accuracy: {exact_match:.4f}\")\n",
    "print(\"Sentence-level Char Accuracy:\", sentence_char_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejEDyJJRtmFu"
   },
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ilB3CXirJLl",
    "outputId": "066c34de-dd41-42cf-9398-7b2c643e020b"
   },
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=128)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def transliterate(text):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Convert Hinglish to Hindi (Devanagari).\n",
    "Handle slang and noisy spellings.\n",
    "\n",
    "### Input:\n",
    "{text}\n",
    "\n",
    "### Output:\n",
    "\"\"\"\n",
    "    out = generate_text(prompt)\n",
    "    return out.split(\"### Output:\")[-1].strip()\n",
    "\n",
    "while True:\n",
    "    text = input(\"Hinglish: \")\n",
    "    if text.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    print(\"Hindi:\", transliterate(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3LZH85trovu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyP62DuDtwaItKRlqtgv++CJ",
   "gpuType": "V5E1",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
